{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggested order to complete this assignment:\n",
    "** Always make sure you watch the lecture videos and read carefully the instructions under every function! \n",
    "1. distances.py\n",
    "2. k_nearest_neighbor.py\n",
    "3. collaborative_filtering.py\n",
    "\n",
    "load_movelens.py is only needed for the free response questions, so the order does not really matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distances.py\n",
    "1. Check lectures for the formulas\n",
    "2. For each distance function, the inputs are a M * K np array (X) and a N * K np array (Y). The output should be a M * N array, where entry [i, j] is the distance between ith row of X and jth row of Y\n",
    "\n",
    "Tip: there are many ways to implement these functions, but we strongly recommend you to use numpy methods (particularly aggregate functions) to speed up the run time. If these distance functions are not optimized, it may take a very long time to run the code needed for FR questions. \n",
    "\n",
    "So here are some useful functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,3])\n",
    "Y = np.array([1,4,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.324555320336759"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X-Y, ord = None)\n",
    "#Note: ord = None gives Euclidean distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X-Y, ord = 1)\n",
    "#Note: ord = 1 gives Manhattan distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt([1, 4, 9, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot([-1, 2, 3], [4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square([-1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k_nearest_neighbors.py\n",
    "1. fit function: think about whether there is an actual training process for KNN models...\n",
    "2. predict function. For each row (i.e. each data point) in the input features matrix: \n",
    "<br>\n",
    "    a. find its K nearest neighbor from the training feature sets. You need use the functions implemented in distances.py: compute the distances --> sort the training data based on distances --> get the K nearest neighbors.\n",
    "<br>\n",
    "    b. if ignore_first = True, skip the closest neighbor (so you want to find K+1 nearest neighbors and get rid of the first one)\n",
    "<br>\n",
    "    c. use the specified aggregator to predict the class of that data point. For example, if K = 5 and aggregator = mode, the classes of 5 nearest neighbors are [0,0,2,3,4] --> the prediction for that data point will be 0. \n",
    "<br>\n",
    "    d. do this for every row in the input features matrix\n",
    "<br>\n",
    "<br>\n",
    "Tip: note that the prediction results directly depends on the training data (meaning that we do not build a model in fit function and use that model for prediction). Therefore you need to access training data in the predict function - how do you do that? \n",
    "\n",
    "\n",
    "Here are some useful functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2   1   3 100]\n",
      "[1 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1,-2,100,3])\n",
    "print(np.sort(arr, axis=0))     # sorts array\n",
    "print(np.argsort(arr, axis=0))  # returns idices of sorted array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collaborative_filtering.py\n",
    "Goal is to predict a person's rating by using the ratings of their K nearest neighbors\n",
    "<br>\n",
    "1. Essentially, we want to find K nearest neighbors for every user (i.e. every row) in the input features. Then we use the information from those K nearest neighbors to predict the ratings for a user. Note that we want to predict a user's ratings for all movies, and we only replace 0 ratings with the prediction results. \n",
    "<br>\n",
    "2. In this case, we do not have an explicit target array. You will be using the same data as training features and  training targets. \n",
    "<br>\n",
    "3. When you call KNN.predict, make sure you set ignore_first to be True. Otherwise, a data point's nearest neighbor will always be itself, which is not helpful for prediction. \n",
    "<br>\n",
    "\n",
    "p.s.: when you answer FR questions, it is possible that after imputation, there are still a few zeros in the data. This just means that a user's nearest neighbors do not rate that movie either... But as long as your collaborative_filtering model is working correctly, a few zeros will not affect the MSEs much. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0, 2, 3, 4, 5, 5, 4, 3, 2, 0, 0, 0])\n",
    "print(np.argwhere(x == 0)) #helpful when you decide which entries you need to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
